{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import nibabel as nib \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.78437651960053, -0.7854122403153297)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check which statistic is most useful to train model with segmentation masks\n",
    "# statistics include: mean, standard deviation, variance, skewnee, kurtosis, entropy\n",
    "\n",
    "#load in the data\n",
    "hard_image = '/media/krishar1/Elements1/AnatomyConstrainedMultipathGAN/B30f_B50f/hard_masked/118866/118866.nii.gz'\n",
    "soft_image = '/media/krishar1/Elements1/AnatomyConstrainedMultipathGAN/B30f_B50f/soft_masked/118866/118866.nii.gz'\n",
    "hard_img = nib.load(hard_image)\n",
    "soft_img = nib.load(soft_image)\n",
    "hard_data = hard_img.get_fdata()\n",
    "soft_data = soft_img.get_fdata()\n",
    "\n",
    "#Clip and normalize the image \n",
    "clipped_hard = np.clip(hard_data, -1024, 3072)\n",
    "clipped_soft = np.clip(soft_data, -1024, 3072)\n",
    "normalizer = interp1d([-1024,3072], [-1,1])\n",
    "norm_data_hard = normalizer(clipped_hard)\n",
    "norm_data_soft = normalizer(clipped_soft)\n",
    "\n",
    "#calculate the statistics\n",
    "hard_mean = np.mean(norm_data_hard)\n",
    "soft_mean = np.mean(norm_data_soft)\n",
    "hard_mean, soft_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_slice = nib.load(\"/home-local/Kernel_Conversion/MultipathKernelConversion_forA6000/multipath_data_journalextension/train_ge_bone_hard/119740_098.nii.gz\")\n",
    "soft_slice = nib.load(\"/home-local/Kernel_Conversion/MultipathKernelConversion_forA6000/multipath_data_journalextension/train_ge_bone_soft/119740_098.nii.gz\")\n",
    "hard_mask_slice = nib.load(\"/fs5/p_masi/krishar1/MIDL/STANDARD_BONE/hard_slices/119740_098.nii.gz\")\n",
    "soft_mask_slice = nib.load(\"/fs5/p_masi/krishar1/MIDL/STANDARD_BONE/soft_slices/119740_098.nii.gz\")\n",
    "\n",
    "hard_slice_data = hard_slice.get_fdata()[:,:,0]\n",
    "soft_slice_data = soft_slice.get_fdata()[:,:,0]\n",
    "hard_mask_slice_data = hard_mask_slice.get_fdata()[:,:,0]\n",
    "soft_mask_slice_data = soft_mask_slice.get_fdata()[:,:,0]\n",
    "\n",
    "normalizer = interp1d([-1024,3072], [-1,1])\n",
    "clipped_hard = np.clip(hard_slice_data, -1024, 3072)\n",
    "clipped_soft = np.clip(soft_slice_data, -1024, 3072)\n",
    "norm_data_hard = normalizer(clipped_hard)\n",
    "norm_data_soft = normalizer(clipped_soft)\n",
    "\n",
    "#Check the unique values in the mask\n",
    "np.unique(hard_mask_slice_data), np.unique(soft_mask_slice_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.190911822998083,\n",
       " -6.202749545012664,\n",
       " 0.9991052214759946,\n",
       " 0.6840271616155018)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For every label in the mask, calculate the mean for the hard and soft image \n",
    "hard_means = []\n",
    "soft_means = []\n",
    "hard_std = []\n",
    "soft_std = []\n",
    "for label in np.unique(hard_mask_slice_data):\n",
    "    if label == 0:\n",
    "        continue\n",
    "    hard_means.append(np.mean(norm_data_hard[hard_mask_slice_data == label]))\n",
    "    soft_means.append(np.mean(norm_data_soft[soft_mask_slice_data == label]))\n",
    "    hard_std.append(np.std(norm_data_hard[hard_mask_slice_data == label]))\n",
    "    soft_std.append(np.std(norm_data_soft[soft_mask_slice_data == label]))\n",
    "\n",
    "#Sum hard and soft means\n",
    "hard_sum_mean = np.sum(hard_means)\n",
    "soft_sum_mean = np.sum(soft_means)\n",
    "\n",
    "hard_sum_std = np.sum(hard_std)\n",
    "soft_sum_std = np.sum(soft_std)\n",
    "hard_sum_mean, soft_sum_mean, hard_sum_std, soft_sum_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm_data_hard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3869288/4120792405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Convert numpy array to a pytroch tensor of size (1,1,512,512)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhard_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_data_hard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msoft_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_data_soft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhard_mask_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhard_mask_slice_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msoft_mask_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoft_mask_slice_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'norm_data_hard' is not defined"
     ]
    }
   ],
   "source": [
    "#Convert numpy array to a pytroch tensor of size (1,1,512,512)\n",
    "hard_tensor = torch.tensor(norm_data_hard).unsqueeze(0).unsqueeze(0)\n",
    "soft_tensor = torch.tensor(norm_data_soft).unsqueeze(0).unsqueeze(0)\n",
    "hard_mask_tensor = torch.tensor(hard_mask_slice_data).unsqueeze(0).unsqueeze(0)\n",
    "soft_mask_tensor = torch.tensor(soft_mask_slice_data).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "#Masks have multiple label, compute mean for each label\n",
    "hard_means = []\n",
    "soft_means = []\n",
    "hard_std = []\n",
    "soft_std = []\n",
    "for label in np.unique(hard_mask_tensor):\n",
    "    if label == 0:\n",
    "        continue\n",
    "    hard_means.append(torch.mean(hard_tensor[hard_mask_tensor == label]))\n",
    "    soft_means.append(torch.mean(soft_tensor[soft_mask_tensor == label]))\n",
    "    hard_std.append(torch.std(hard_tensor[hard_mask_tensor == label]))\n",
    "    soft_std.append(torch.std(soft_tensor[soft_mask_tensor == label]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-6.1909, dtype=torch.float64),\n",
       " tensor(-6.2027, dtype=torch.float64),\n",
       " tensor(0.9997, dtype=torch.float64),\n",
       " tensor(0.6844, dtype=torch.float64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_sum_mean = torch.sum(torch.tensor(hard_means))\n",
    "soft_sum_mean = torch.sum(torch.tensor(soft_means))\n",
    "hard_sum_std = torch.sum(torch.tensor(hard_std))\n",
    "soft_sum_std = torch.sum(torch.tensor(soft_std))\n",
    "\n",
    "hard_sum_mean, soft_sum_mean, hard_sum_std, soft_sum_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.,  1.,  2.,  3.,  4.,  8., 10., 13., 15., 16., 18., 25., 26.],\n",
       "        dtype=torch.float64),\n",
       " tensor([ 0.,  1.,  2.,  3.,  4.,  8., 10., 13., 15., 16., 18., 25., 26.],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(hard_mask_tensor), torch.unique(soft_mask_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  2.,  3.,  4.,  8., 10., 13., 15., 16., 18., 25., 26.]),\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  8., 10., 13., 15., 16., 18., 25., 26.]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(hard_mask_tensor), np.unique(soft_mask_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_mask_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
