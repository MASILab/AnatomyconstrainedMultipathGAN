{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import nibabel as nib \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which statistic is most useful to train model with segmentation masks\n",
    "# statistics include: mean, standard deviation, variance, skewnee, kurtosis, entropy\n",
    "\n",
    "#load in the data\n",
    "hard_image = '/valiant02/masi/krishar1/TotalSegmentator_masks_CTkernel_MIDL/B30f_B50f/hard_masked/119178/119178.nii.gz'\n",
    "soft_image = '/valiant02/masi/krishar1/TotalSegmentator_masks_CTkernel_MIDL/B30f_B50f/soft_masked/119178/119178.nii.gz'\n",
    "hard_img = nib.load(hard_image)\n",
    "soft_img = nib.load(soft_image)\n",
    "hard_data = hard_img.get_fdata()\n",
    "soft_data = soft_img.get_fdata()\n",
    "\n",
    "#calculate the statistics\n",
    "hard_mean = np.mean(hard_data)\n",
    "soft_mean = np.mean(soft_data)\n",
    "hard_std = np.std(hard_data)\n",
    "soft_std = np.std(soft_data)\n",
    "hard_var = np.var(hard_data)\n",
    "\n",
    "hard_ent = entropy(hard_data.flatten())\n",
    "soft_ent = entropy(soft_data.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29.43140775659209,\n",
       " 114.1758257725864,\n",
       " -103.8989985012111,\n",
       " 98.41642368046736,\n",
       " 31.53152766845362,\n",
       " 50.26436155494546,\n",
       " -101.62994936328461,\n",
       " 41.0206963352474)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load multiple masks. Explore mean and std of the image within the mask \n",
    "muscle_hard = nib.load('/valiant02/masi/krishar1/TotalSegmentator_masks_CTkernel_MIDL/B30f_B50f/hard_masked/119178/segmentations/skeletal_muscle.nii.gz')\n",
    "fat_hard = nib.load('/valiant02/masi/krishar1/TotalSegmentator_masks_CTkernel_MIDL/B30f_B50f/hard_masked/119178/segmentations/subcutaneous_fat.nii.gz')\n",
    "muscle_soft = nib.load('/valiant02/masi/krishar1/TotalSegmentator_masks_CTkernel_MIDL/B30f_B50f/soft_masked/119178/segmentations/skeletal_muscle.nii.gz')\n",
    "fat_soft = nib.load('/valiant02/masi/krishar1/TotalSegmentator_masks_CTkernel_MIDL/B30f_B50f/soft_masked/119178/segmentations/subcutaneous_fat.nii.gz')\n",
    "muscle_data = muscle_hard.get_fdata()\n",
    "fat_data = fat_hard.get_fdata()\n",
    "muscle_soft_data = muscle_soft.get_fdata()\n",
    "fat_soft_data = fat_soft.get_fdata()\n",
    "\n",
    "#calculate the statistics using the muscle mask in the image \n",
    "muscle_mean = np.mean(hard_data[muscle_data == 1])\n",
    "muscle_std = np.std(hard_data[muscle_data == 1])\n",
    "fat_mean = np.mean(hard_data[fat_data == 1])\n",
    "fat_std = np.std(hard_data[fat_data == 1])\n",
    "\n",
    "muscle_soft_mean = np.mean(soft_data[muscle_soft_data == 1])\n",
    "muscle_soft_std = np.std(soft_data[muscle_soft_data == 1])\n",
    "fat_soft_mean = np.mean(soft_data[fat_soft_data == 1])\n",
    "fat_soft_std = np.std(soft_data[fat_soft_data == 1])\n",
    "\n",
    "muscle_mean, muscle_std, fat_mean, fat_std, muscle_soft_mean, muscle_soft_std, fat_soft_mean, fat_soft_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, -inf, -inf, -inf)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entropy of the image within the muscle mask\n",
    "muscle_hard_ent = entropy(hard_data[muscle_data == 1].flatten())\n",
    "fat_hard_ent = entropy(hard_data[fat_data == 1].flatten())\n",
    "muscle_soft_ent = entropy(soft_data[muscle_soft_data == 1].flatten())\n",
    "fat_soft_ent = entropy(soft_data[fat_soft_data == 1].flatten())\n",
    "\n",
    "muscle_hard_ent, fat_hard_ent, muscle_soft_ent, fat_soft_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: 7.817729103761303\n"
     ]
    }
   ],
   "source": [
    "def calculate_entropy(data):\n",
    "    # Calculate the histogram of the data\n",
    "    hist, bin_edges = np.histogram(data, bins=256, density=True)\n",
    "    \n",
    "    # Normalize the histogram to get probabilities\n",
    "    probabilities = hist / np.sum(hist)\n",
    "    \n",
    "    # Remove zero probabilities to avoid log(0)\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.529090493993861, 5.453430030186957)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_hard = calculate_entropy(hard_data)\n",
    "entropy_soft = calculate_entropy(soft_data)\n",
    "entropy_hard, entropy_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
