{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import nibabel as nib \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.78437651960053, -0.7854122403153297)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check which statistic is most useful to train model with segmentation masks\n",
    "# statistics include: mean, standard deviation, variance, skewnee, kurtosis, entropy\n",
    "\n",
    "#load in the data\n",
    "hard_image = '/media/krishar1/Elements1/AnatomyConstrainedMultipathGAN/B30f_B50f/hard_masked/118866/118866.nii.gz'\n",
    "soft_image = '/media/krishar1/Elements1/AnatomyConstrainedMultipathGAN/B30f_B50f/soft_masked/118866/118866.nii.gz'\n",
    "hard_img = nib.load(hard_image)\n",
    "soft_img = nib.load(soft_image)\n",
    "hard_data = hard_img.get_fdata()\n",
    "soft_data = soft_img.get_fdata()\n",
    "\n",
    "#Clip and normalize the image \n",
    "clipped_hard = np.clip(hard_data, -1024, 3072)\n",
    "clipped_soft = np.clip(soft_data, -1024, 3072)\n",
    "normalizer = interp1d([-1024,3072], [-1,1])\n",
    "norm_data_hard = normalizer(clipped_hard)\n",
    "norm_data_soft = normalizer(clipped_soft)\n",
    "\n",
    "#calculate the statistics\n",
    "hard_mean = np.mean(norm_data_hard)\n",
    "soft_mean = np.mean(norm_data_soft)\n",
    "hard_mean, soft_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  1.,  2.,  3.,  4.,  8., 10., 13., 15., 16., 18., 25., 26.]),\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  8., 10., 13., 15., 16., 18., 25., 26.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_slice = nib.load(\"/home-local/Kernel_Conversion/MultipathKernelConversion_forA6000/multipath_data_journalextension/train_ge_bone_hard/119740_098.nii.gz\")\n",
    "soft_slice = nib.load(\"/home-local/Kernel_Conversion/MultipathKernelConversion_forA6000/multipath_data_journalextension/train_ge_bone_soft/119740_098.nii.gz\")\n",
    "hard_mask_slice = nib.load(\"/fs5/p_masi/krishar1/MIDL/STANDARD_BONE/hard_slices/119740_098.nii.gz\")\n",
    "soft_mask_slice = nib.load(\"/fs5/p_masi/krishar1/MIDL/STANDARD_BONE/soft_slices/119740_098.nii.gz\")\n",
    "\n",
    "hard_slice_data = hard_slice.get_fdata()[:,:,0]\n",
    "soft_slice_data = soft_slice.get_fdata()[:,:,0]\n",
    "hard_mask_slice_data = hard_mask_slice.get_fdata()[:,:,0]\n",
    "soft_mask_slice_data = soft_mask_slice.get_fdata()[:,:,0]\n",
    "\n",
    "normalizer = interp1d([-1024,3072], [-1,1])\n",
    "clipped_hard = np.clip(hard_slice_data, -1024, 3072)\n",
    "clipped_soft = np.clip(soft_slice_data, -1024, 3072)\n",
    "norm_data_hard = normalizer(clipped_hard)\n",
    "norm_data_soft = normalizer(clipped_soft)\n",
    "\n",
    "#Check the unique values in the mask\n",
    "np.unique(hard_mask_slice_data), np.unique(soft_mask_slice_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-6.190911822998083,\n",
       " -6.202749545012664,\n",
       " 0.9991052214759946,\n",
       " 0.6840271616155018)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For every label in the mask, calculate the mean for the hard and soft image \n",
    "hard_means = []\n",
    "soft_means = []\n",
    "hard_std = []\n",
    "soft_std = []\n",
    "for label in np.unique(hard_mask_slice_data):\n",
    "    if label == 0:\n",
    "        continue\n",
    "    hard_means.append(np.mean(norm_data_hard[hard_mask_slice_data == label]))\n",
    "    soft_means.append(np.mean(norm_data_soft[soft_mask_slice_data == label]))\n",
    "    hard_std.append(np.std(norm_data_hard[hard_mask_slice_data == label]))\n",
    "    soft_std.append(np.std(norm_data_soft[soft_mask_slice_data == label]))\n",
    "\n",
    "#Sum hard and soft means\n",
    "hard_sum_mean = np.sum(hard_means)\n",
    "soft_sum_mean = np.sum(soft_means)\n",
    "\n",
    "hard_sum_std = np.sum(hard_std)\n",
    "soft_sum_std = np.sum(soft_std)\n",
    "hard_sum_mean, soft_sum_mean, hard_sum_std, soft_sum_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert numpy array to a pytroch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lung2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
